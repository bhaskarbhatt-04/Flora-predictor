{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/content/drive/MyDrive/Florapedia_V/archive/flowers'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "data = []\n",
    "\n",
    "def make_data():\n",
    "    for category in categories:\n",
    "      path = os.path.join(data_dir, category)\n",
    "      print(path)\n",
    "      label = categories.index(category)\n",
    "\n",
    "      for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        try :\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "          image = cv2.resize(image, (224, 224))\n",
    "\n",
    "          image = np.array(image, dtype=np.float32)\n",
    "\n",
    "          data.append([image,label])\n",
    "\n",
    "        except Exception as e:\n",
    "          pass\n",
    "    \n",
    "    print(len(data))   \n",
    "\n",
    "    pik = open('data.pickle', 'wb')\n",
    "    pickle.dump(data,pik)\n",
    "    pik.close()\n",
    "\n",
    "\n",
    "\n",
    "make_data()\n",
    "\n",
    "def load_data():\n",
    "  pick = open('data.pickle','rb')\n",
    "  data = pickle.load(pick)\n",
    "  pick.close()\n",
    "\n",
    "  np.random.shuffle(data)\n",
    "\n",
    "  feature = []\n",
    "  labels = []\n",
    "\n",
    "  for img, label in data:\n",
    "    feature.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "  feature = np.array(feature, dtype=np.float32)\n",
    "  labels=np.array(labels)\n",
    "\n",
    "  feature = feature/255.0\n",
    "\n",
    "  return [feature, labels]\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "(feature, labels) = load_data()\n",
    "\n",
    "(x_train, x_test, y_train, y_yest) = train_test_split(feature,labels, test_size = 0.1)\n",
    "\n",
    "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "input_layer = tf.keras.layers.Input([224,224,3])\n",
    "\n",
    "\n",
    "conv1=tf.keras.layers.Conv2D(filters = 32, kernel_size=(5,5), padding='Same',\n",
    "                             activation = 'relu')(input_layer)\n",
    "\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "                             \n",
    "\n",
    "\n",
    "conv2=tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='Same',\n",
    "                             activation = 'relu')(pool1)\n",
    "\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv2)\n",
    "\n",
    "\n",
    "\n",
    "conv3=tf.keras.layers.Conv2D(filters = 96, kernel_size=(3,3), padding='Same',\n",
    "                             activation = 'relu')(pool2)\n",
    "\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv3)\n",
    "\n",
    "\n",
    "\n",
    "conv4=tf.keras.layers.Conv2D(filters = 96, kernel_size=(3,3), padding='Same',\n",
    "                             activation = 'relu')(pool3)\n",
    "\n",
    "pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv3)\n",
    "\n",
    "\n",
    "flt1 = tf.keras.layers.Flatten()(pool4)\n",
    "\n",
    "dn1 = tf.keras.layers.Dense(512,activation='relu')(flt1)\n",
    "out = tf.keras.layers.Dense(5, activation='softmax')(dn1)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(input_layer, out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 100, epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
